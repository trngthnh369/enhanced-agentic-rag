# enhanced_rag.py
import pandas as pd
import google.generativeai as genai
from dotenv import load_dotenv
import requests
import os
import numpy as np
import chromadb
import json
import re
from typing import Dict, List, Any, Tuple, Optional
from enum import Enum
import time

load_dotenv()

# Configure Gemini
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

chroma_client = chromadb.PersistentClient("db")
collection_name = 'products'

class InformationSource(Enum):
    VECTOR_DATABASE = "vector_database"
    SHOP_INFO = "shop_info"
    INTERNET = "internet"
    NONE = "none"

class QueryProcessor:
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-2.0-flash')

    def rewrite_query(self, original_query: str, context: str = "") -> str:
        """Step 1: Rewrite the original query for better understanding"""
        context_prompt = f"\nNgá»¯ cáº£nh bá»• sung: {context}" if context else ""
        
        prompt = f"""
        Báº¡n lÃ  má»™t chuyÃªn gia xá»­ lÃ½ cÃ¢u há»i vá» Ä‘iá»‡n thoáº¡i di Ä‘á»™ng vÃ  cá»­a hÃ ng. 
        HÃ£y viáº¿t láº¡i cÃ¢u há»i sau Ä‘á»ƒ lÃ m cho nÃ³ rÃµ rÃ ng, cá»¥ thá»ƒ vÃ  dá»… tÃ¬m kiáº¿m hÆ¡n:

        CÃ¢u há»i gá»‘c: "{original_query}"{context_prompt}

        YÃªu cáº§u viáº¿t láº¡i:
        1. Giá»¯ nguyÃªn Ã½ nghÄ©a chÃ­nh cá»§a cÃ¢u há»i
        2. LÃ m rÃµ cÃ¡c tá»« khÃ³a quan trá»ng vá» sáº£n pháº©m, giÃ¡ cáº£, thÃ´ng sá»‘
        3. Bá»• sung ngá»¯ cáº£nh cáº§n thiáº¿t cho viá»‡c tÃ¬m kiáº¿m
        4. Äáº£m báº£o cÃ¢u há»i phÃ¹ há»£p vá»›i viá»‡c tÃ¬m kiáº¿m trong database sáº£n pháº©m hoáº·c thÃ´ng tin cá»­a hÃ ng
        5. Chá»‰ tráº£ vá» cÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c viáº¿t láº¡i, khÃ´ng giáº£i thÃ­ch thÃªm

        CÃ¢u há»i Ä‘Ã£ viáº¿t láº¡i:
        """
        
        try:
            response = self.model.generate_content(prompt)
            rewritten = response.text.strip().strip('"')
            print(f"ğŸ”„ Query rewritten: {original_query} -> {rewritten}")
            return rewritten
        except Exception as e:
            print(f"âŒ Error in query rewriting: {e}")
            return original_query

    def need_additional_info(self, query: str) -> bool:
        """Step 2: Determine if additional information is needed"""
        prompt = f"""
        PhÃ¢n tÃ­ch cÃ¢u há»i sau vá» Ä‘iá»‡n thoáº¡i di Ä‘á»™ng/cá»­a hÃ ng vÃ  quyáº¿t Ä‘á»‹nh cÃ³ cáº§n truy xuáº¥t thÃ´ng tin bá»• sung hay khÃ´ng:

        CÃ¢u há»i: "{query}"

        CÃ¡c trÆ°á»ng há»£p Cáº¦N truy xuáº¥t thÃ´ng tin:
        - Há»i vá» sáº£n pháº©m cá»¥ thá»ƒ (Nokia, Samsung, iPhone...)
        - Há»i vá» giÃ¡ cáº£, khuyáº¿n mÃ£i
        - Há»i vá» thÃ´ng sá»‘ ká»¹ thuáº­t
        - Há»i vá» Ä‘á»‹a chá»‰ cá»­a hÃ ng, giá» má»Ÿ cá»­a
        - Há»i so sÃ¡nh sáº£n pháº©m
        - Há»i vá» chÃ­nh sÃ¡ch, báº£o hÃ nh

        CÃ¡c trÆ°á»ng há»£p KHÃ”NG cáº§n truy xuáº¥t:
        - ChÃ o há»i Ä‘Æ¡n giáº£n
        - CÃ¢u há»i chung chung vá» cÃ´ng nghá»‡
        - YÃªu cáº§u giáº£i thÃ­ch khÃ¡i niá»‡m cÆ¡ báº£n

        HÃ£y tráº£ lá»i CHÃNH XÃC má»™t tá»«:
        - "YES" náº¿u cáº§n truy xuáº¥t thÃ´ng tin tá»« database/internet
        - "NO" náº¿u cÃ³ thá»ƒ tráº£ lá»i báº±ng kiáº¿n thá»©c chung

        Tráº£ lá»i:
        """
        
        try:
            response = self.model.generate_content(prompt)
            answer = response.text.strip().upper()
            need_info = answer == "YES"
            print(f"ğŸ“Š Need additional info: {need_info} for query: {query}")
            return need_info
        except Exception as e:
            print(f"âŒ Error in need_additional_info: {e}")
            return True

    def determine_information_source(self, query: str) -> List[InformationSource]:
        """Step 3: Determine which information sources to use"""
        prompt = f"""
        PhÃ¢n tÃ­ch cÃ¢u há»i vá» Ä‘iá»‡n thoáº¡i/cá»­a hÃ ng vÃ  xÃ¡c Ä‘á»‹nh nguá»“n thÃ´ng tin phÃ¹ há»£p:

        CÃ¢u há»i: "{query}"

        Nguá»“n thÃ´ng tin cÃ³ sáºµn:
        1. "vector_database" - ThÃ´ng tin sáº£n pháº©m chi tiáº¿t (Nokia, Samsung...), giÃ¡ cáº£, thÃ´ng sá»‘ ká»¹ thuáº­t, khuyáº¿n mÃ£i
        2. "shop_info" - ThÃ´ng tin cá»­a hÃ ng: Ä‘á»‹a chá»‰, giá» má»Ÿ cá»­a, chi nhÃ¡nh, liÃªn há»‡
        3. "internet" - TÃ¬m kiáº¿m thÃ´ng tin má»›i nháº¥t tá»« web khi database khÃ´ng Ä‘á»§
        4. "none" - KhÃ´ng cáº§n nguá»“n bá»• sung

        Quy táº¯c chá»n nguá»“n:
        - Há»i vá» sáº£n pháº©m/giÃ¡/thÃ´ng sá»‘ â†’ vector_database
        - Há»i vá» Ä‘á»‹a chá»‰/giá» má»Ÿ cá»­a/cá»­a hÃ ng â†’ shop_info  
        - Cáº§n thÃ´ng tin má»›i nháº¥t/sáº£n pháº©m khÃ´ng cÃ³ trong DB â†’ internet
        - CÃ³ thá»ƒ dÃ¹ng nhiá»u nguá»“n káº¿t há»£p

        Tráº£ lá»i báº±ng JSON format:
        {{"sources": ["vector_database"], "reasoning": "lÃ½ do chá»n nguá»“n nÃ y"}}

        Tráº£ lá»i:
        """
        
        try:
            response = self.model.generate_content(prompt)
            # Clean JSON response
            json_text = response.text.strip()
            if json_text.startswith('```json'):
                json_text = json_text.replace('```json', '').replace('```', '')
            
            result = json.loads(json_text)
            sources = []
            for source in result.get("sources", []):
                try:
                    sources.append(InformationSource(source))
                except ValueError:
                    print(f"âš ï¸ Invalid source: {source}")
                    continue
            
            if not sources:
                sources = [InformationSource.VECTOR_DATABASE]
                
            print(f"ğŸ¯ Selected sources: {[s.value for s in sources]}")
            print(f"ğŸ’­ Reasoning: {result.get('reasoning', 'No reasoning provided')}")
            return sources
            
        except Exception as e:
            print(f"âŒ Error in determine_information_source: {e}")
            return [InformationSource.VECTOR_DATABASE]

    def evaluate_response_quality(self, original_query: str, response: str) -> Tuple[bool, str]:
        """Step 4: Evaluate if the response adequately answers the query"""
        prompt = f"""
        ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i cho cÃ¢u há»i vá» Ä‘iá»‡n thoáº¡i/cá»­a hÃ ng:

        CÃ¢u há»i gá»‘c: "{original_query}"
        CÃ¢u tráº£ lá»i: "{response}"

        TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡:
        1. CÃ³ tráº£ lá»i Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i khÃ´ng?
        2. ThÃ´ng tin cÃ³ chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ khÃ´ng?
        3. CÃ³ cung cáº¥p chi tiáº¿t cá»¥ thá»ƒ (giÃ¡, thÃ´ng sá»‘, Ä‘á»‹a chá»‰...) khi cáº§n?
        4. CÃ³ liÃªn quan trá»±c tiáº¿p Ä‘áº¿n cÃ¢u há»i khÃ´ng?
        5. CÃ³ Ä‘á» xuáº¥t thÃªm thÃ´ng tin há»¯u Ã­ch khÃ´ng?

        Tráº£ lá»i báº±ng JSON format:
        {{
            "quality": "YES" hoáº·c "NO",
            "feedback": "nháº­n xÃ©t chi tiáº¿t vá» cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i",
            "missing_info": "thÃ´ng tin cÃ²n thiáº¿u (náº¿u cÃ³)"
        }}

        Tráº£ lá»i:
        """
        
        try:
            response_eval = self.model.generate_content(prompt)
            json_text = response_eval.text.strip()
            if json_text.startswith('```json'):
                json_text = json_text.replace('```json', '').replace('```', '')
                
            result = json.loads(json_text)
            quality_good = result.get("quality", "NO") == "YES"
            feedback = result.get("feedback", "No feedback provided")
            
            print(f"â­ Response quality: {quality_good}")
            print(f"ğŸ“ Feedback: {feedback}")
            
            return quality_good, feedback
            
        except Exception as e:
            print(f"âŒ Error in evaluate_response_quality: {e}")
            return True, "Evaluation error"

class InternetSearchTool:
    def __init__(self):
        self.serpapi_key = os.getenv("SERPAPI_KEY")
        self.model = genai.GenerativeModel('gemini-2.0-flash')

    def search_web(self, query: str) -> str:
        """Search the internet using SerpAPI"""
        if not self.serpapi_key:
            return "KhÃ´ng cÃ³ API key cho tÃ¬m kiáº¿m internet."

        try:
            url = "https://serpapi.com/search"
            params = {
                "q": f"{query} Ä‘iá»‡n thoáº¡i mobile phone Vietnam",
                "api_key": self.serpapi_key,
                "engine": "google",
                "google_domain": "google.com.vn",
                "gl": "vn",
                "hl": "vi",
                "num": 5
            }
            
            response = requests.get(url, params=params)
            if response.status_code != 200:
                return f"Lá»—i tÃ¬m kiáº¿m: HTTP {response.status_code}"
                
            data = response.json()
            
            # Extract useful information
            results = []
            if "organic_results" in data:
                for result in data["organic_results"][:3]:
                    title = result.get("title", "")
                    snippet = result.get("snippet", "")
                    results.append(f"- {title}: {snippet}")
            
            if results:
                return f"ThÃ´ng tin tá»« internet:\n" + "\n".join(results)
            else:
                return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trÃªn internet."
                
        except Exception as e:
            print(f"âŒ Internet search error: {e}")
            return f"Lá»—i khi tÃ¬m kiáº¿m trÃªn internet: {str(e)}"

class EnhancedRAG:
    def __init__(self):
        self.query_processor = QueryProcessor()
        self.internet_search = InternetSearchTool()
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        self.max_iterations = 3
        
    def get_embedding(self, text: str) -> list[float]:
        """Generate embeddings using Gemini"""
        try:
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=text,
                task_type="retrieval_query"
            )
            return result['embedding']
        except Exception as e:
            print(f"âŒ Error generating embedding: {e}")
            return []

    def retrieve_from_vector_db(self, query: str) -> str:
        """Retrieve information from vector database"""
        try:
            collection = chroma_client.get_collection(name=collection_name)
            query_embedding = self.get_embedding(query)
            
            if not query_embedding:
                return "KhÃ´ng thá»ƒ táº¡o embedding cho cÃ¢u truy váº¥n."
            
            query_embedding = np.array(query_embedding)
            query_embedding = query_embedding / np.linalg.norm(query_embedding)

            search_results = collection.query(
                query_embeddings=query_embedding.tolist(), 
                n_results=int(os.getenv("MAX_RESULTS_VECTOR_DB", 5))  # Increased for better coverage
            )

            metadatas = search_results.get('metadatas', [])
            search_result = ""
            
            for i, metadata_list in enumerate(metadatas):
                if isinstance(metadata_list, list):
                    for j, metadata in enumerate(metadata_list):
                        if isinstance(metadata, dict):
                            combined_text = metadata.get('information', 'No text available').strip()
                            search_result += f"{i+1}. {combined_text}\n\n"
                            
            result = search_result if search_result else "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong database."
            print(f"ğŸ—„ï¸ Vector DB result length: {len(result)} chars")
            return result
            
        except Exception as e:
            print(f"âŒ Error in retrieve_from_vector_db: {e}")
            return "Lá»—i khi truy xuáº¥t dá»¯ liá»‡u tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u."

    def retrieve_shop_info(self) -> str:
        """Retrieve shop information from Google Sheets"""
        try:
            import gspread
            from oauth2client.service_account import ServiceAccountCredentials

            scope = ['https://spreadsheets.google.com/feeds',
                    'https://www.googleapis.com/auth/drive']

            credentials = ServiceAccountCredentials.from_json_keyfile_name(
                os.getenv("GOOGLE_SHEETS_CREDENTIAL_FILE"), scope
            )
            client = gspread.authorize(credentials)
            sheet = client.open_by_url(
                'https://docs.google.com/spreadsheets/d/1mOkgLyo1oedOG1nlvoSHpqK9-fTFzE9ysLuKob9TXlg'
            ).sheet1

            data = sheet.get_all_records()
            result = json.dumps(data, ensure_ascii=False, indent=2)
            print(f"ğŸª Shop info retrieved: {len(result)} chars")
            return result
            
        except Exception as e:
            print(f"âŒ Error in retrieve_shop_info: {e}")
            return "Lá»—i khi truy xuáº¥t thÃ´ng tin cá»­a hÃ ng."

    def retrieve_information(self, query: str, sources: List[InformationSource]) -> str:
        """Retrieve information from specified sources"""
        retrieved_info = []
        
        for source in sources:
            print(f"ğŸ” Retrieving from: {source.value}")
            
            if source == InformationSource.VECTOR_DATABASE:
                info = self.retrieve_from_vector_db(query)
                if info and "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin" not in info:
                    retrieved_info.append(f"ğŸ“± ThÃ´ng tin sáº£n pháº©m:\n{info}")
                
            elif source == InformationSource.SHOP_INFO:
                info = self.retrieve_shop_info()
                if info and "Lá»—i" not in info:
                    retrieved_info.append(f"ğŸª ThÃ´ng tin cá»­a hÃ ng:\n{info}")
                
            elif source == InformationSource.INTERNET:
                info = self.internet_search.search_web(query)
                if info and "Lá»—i" not in info:
                    retrieved_info.append(f"ğŸŒ Tá»« internet:\n{info}")
        
        result = "\n\n---\n\n".join(retrieved_info)
        print(f"ğŸ“š Total retrieved info length: {len(result)} chars")
        return result

    def generate_response(self, original_query: str, updated_query: str, context: str = "") -> str:
        """Generate final response using Gemini"""
        if context:
            prompt = f"""
            Báº¡n lÃ  má»™t chuyÃªn viÃªn tÆ° váº¥n Ä‘iá»‡n thoáº¡i di Ä‘á»™ng chuyÃªn nghiá»‡p táº¡i cá»­a hÃ ng.
            
            ThÃ´ng tin tham kháº£o Ä‘Ã£ Ä‘Æ°á»£c truy xuáº¥t:
            {context}

            CÃ¢u há»i gá»‘c cá»§a khÃ¡ch hÃ ng: {original_query}
            CÃ¢u há»i Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½: {updated_query}

            YÃªu cáº§u tráº£ lá»i:
            1. Tráº£ lá»i chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ dá»±a trÃªn thÃ´ng tin Ä‘Ã£ truy xuáº¥t
            2. Æ¯u tiÃªn thÃ´ng tin cá»¥ thá»ƒ: giÃ¡ cáº£, thÃ´ng sá»‘ ká»¹ thuáº­t, Ä‘á»‹a chá»‰
            3. Náº¿u cÃ³ nhiá»u lá»±a chá»n, hÃ£y so sÃ¡nh vÃ  Ä‘Æ°a ra gá»£i Ã½
            4. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p
            5. Náº¿u thÃ´ng tin khÃ´ng Ä‘áº§y Ä‘á»§, hÃ£y nÃ³i rÃµ vÃ  gá»£i Ã½ cÃ¡ch tÃ¬m hiá»ƒu thÃªm

            CÃ¢u tráº£ lá»i:
            """
        else:
            prompt = f"""
            Báº¡n lÃ  má»™t chuyÃªn viÃªn tÆ° váº¥n Ä‘iá»‡n thoáº¡i di Ä‘á»™ng chuyÃªn nghiá»‡p.
            
            CÃ¢u há»i cá»§a khÃ¡ch hÃ ng: {original_query}

            YÃªu cáº§u:
            1. Tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c chung vá» Ä‘iá»‡n thoáº¡i di Ä‘á»™ng
            2. Giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p
            3. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
            4. Náº¿u cáº§n thÃ´ng tin cá»¥ thá»ƒ, hÃ£y gá»£i Ã½ khÃ¡ch hÃ ng há»i chi tiáº¿t hÆ¡n

            CÃ¢u tráº£ lá»i:
            """

        try:
            response = self.model.generate_content(prompt)
            result = response.text.strip()
            print(f"ğŸ’¬ Generated response length: {len(result)} chars")
            return result
        except Exception as e:
            print(f"âŒ Error in generate_response: {e}")
            return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ táº¡o cÃ¢u tráº£ lá»i lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i sau."

    def process_query(self, original_query: str) -> str:
        """Main enhanced processing workflow with reasoning and action"""
        print(f"\nğŸš€ Starting Enhanced RAG Processing")
        print(f"ğŸ“ Original query: {original_query}")
        print("="*60)
        
        current_query = original_query
        iteration = 0
        context_feedback = ""
        
        while iteration < self.max_iterations:
            print(f"\nğŸ”„ ITERATION {iteration + 1}/{self.max_iterations}")
            print("-" * 40)
            
            # Step 1: Query Rewriting
            print("1ï¸âƒ£ QUERY REWRITING")
            updated_query = self.query_processor.rewrite_query(current_query, context_feedback)
            
            # Step 2: Information Need Assessment
            print("\n2ï¸âƒ£ INFORMATION NEED ASSESSMENT")
            needs_info = self.query_processor.need_additional_info(updated_query)
            
            if not needs_info:
                print("â„¹ï¸ No additional information needed, generating direct response")
                response = self.generate_response(original_query, updated_query)
            else:
                print("ğŸ” Additional information needed, proceeding to retrieval")
                
                # Step 3: Information Source Selection
                print("\n3ï¸âƒ£ INFORMATION SOURCE SELECTION")
                sources = self.query_processor.determine_information_source(updated_query)
                
                # Step 4: Information Retrieval
                print("\n4ï¸âƒ£ INFORMATION RETRIEVAL")
                context = self.retrieve_information(updated_query, sources)
                
                # Step 5: Response Generation
                print("\n5ï¸âƒ£ RESPONSE GENERATION")
                response = self.generate_response(original_query, updated_query, context)
            
            # Step 6: Response Quality Evaluation
            print("\n6ï¸âƒ£ RESPONSE QUALITY EVALUATION")
            is_good_response, feedback = self.query_processor.evaluate_response_quality(
                original_query, response
            )
            
            if is_good_response:
                print(f"âœ… Response approved after {iteration + 1} iteration(s)")
                print("="*60)
                return response
            
            # Prepare for next iteration
            print(f"ğŸ”„ Response needs improvement, preparing iteration {iteration + 2}")
            context_feedback = feedback
            current_query = f"""
            CÃ¢u há»i gá»‘c: {original_query}
            CÃ¢u tráº£ lá»i trÆ°á»›c chÆ°a Ä‘áº¡t yÃªu cáº§u: {response}
            Pháº£n há»“i: {feedback}
            HÃ£y cáº£i thiá»‡n cÃ¢u há»i Ä‘á»ƒ cÃ³ thá»ƒ truy xuáº¥t thÃ´ng tin tá»‘t hÆ¡n.
            """
            iteration += 1
        
        print(f"âš ï¸ Max iterations reached, returning best available response")
        print("="*60)
        return response

# Global enhanced RAG instance
enhanced_rag = EnhancedRAG()

def enhanced_product_rag(query: str) -> str:
    """Enhanced RAG for product information with reasoning and action"""
    print(f'\nğŸ›ï¸ Enhanced Product RAG initiated')
    return enhanced_rag.process_query(query)

def enhanced_shop_info_rag(query: str) -> str:
    """Enhanced RAG for shop information with reasoning and action"""
    print(f'\nğŸª Enhanced Shop Info RAG initiated')
    return enhanced_rag.process_query(query)